{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the group documentation for the Bennett Hydrology Research Group","text":"<p>Welcome to the official documentation for the Bennett Hydrology Research Group. Our group specializes in the hydrologic sciences with a particular focus on computational methods and machine learning. This documentation serves as a comprehensive resource for current and prospective members of our research group.</p> <p>Here, you will find detailed information on a variety of topics including:</p> <ul> <li>Computing Resources: An overview of the hardware and software tools available for our research.</li> <li>Interesting Code Packages: Descriptions and usage guides for code packages that are particularly useful in our field.</li> <li>Departmental Administrative Procedures: Guidelines and procedures for navigating the administrative aspects of our department.</li> <li>Other Groups of Interest on Campus: Information about other research groups and collaborations within the university.</li> <li>General Information about Graduate School: Tips and advice for succeeding in graduate school, including academic and personal development resources.</li> </ul>"},{"location":"code_of_conduct/","title":"Code of Conduct for members and affiliates","text":"<p>Note</p> <p>This is a living document, it may be worth revisiting from time to time to reflect on our purpose and goals. It is also not a legally binding document, but is shared as a reasonable expectation for participating in our group's activities.</p>"},{"location":"code_of_conduct/#preamble","title":"Preamble","text":"<p>We value the participation of all members and colleagues in our community and want to ensure that all feel welcome, valued, and fulfilled in both personal and professional matters. We also hold our work and communication with others to high standards, and encourage those around us to do the same. To affirm these values and cultivate a positive and productive environment all members of the Bennett research group are expected to uphold these standards. </p>"},{"location":"code_of_conduct/#social-code-of-conduct","title":"Social Code of Conduct","text":"<p>The pursuit of scientific truths and applied advancements is best developed in a friendly, inclusive, and fulfilling environment. To this end, all members of the group are entitled to a space free of harassment and hostility. We ask that all members conduct themselves according to the following principles:</p> <ul> <li>Communication whether in person, online, professional, or personal must remain appropriate in professional contexts and be culturally considerate and inclusive.</li> <li>Harassment, including offensive verbal comments related to gender, sexual orientation, disability, physical appearance, body size, race, religion, deliberate intimidation, stalking, sustained disruption of discussions, inappropriate physical contact, and unwelcome sexual attention will not be tolerated.</li> <li>Be mindful in group discussion so that all can particate and that a variety of viewpoints can be expresses.</li> <li>Take a \"yes and\" perspective. Be generous when attributing credit and praise. Positivity encourages the best work.</li> <li>Mentorship occurs at all career and educational stages. Make efforts to build relationships with your collaborators and communicate not only about technical aspects of work but also about the environment in which that work is situated.</li> </ul>"},{"location":"code_of_conduct/#research-code-of-conduct","title":"Research Code of Conduct","text":"<p>Academic research is rooted in a desire to push our understanding of the world forward. Such work is, by definition, at the edge of our knowledge and should be treated with internal skepticism and researchers should act in accordance with ethical principles ensuring both validity and reproducibility.  Researchers also bring their unique viewpoint and methodological perspective to their work that should be both communicated by investigators and sought to be understood by those participating in the work.</p> <p>At a more basic level, a majority of research products developed by the Bennett research group are anticipated to be computational in nature. Good stewardship of methods, code, and data are all expected. Specific to these points we expect:</p> <ul> <li>All code used to produce publications made public and be cleaned to a reasonable standard (not rely on hidden variables, clearly have workflow steps ordered, have a computational environment specified). Code possibly useful to future collaborators should be made public on the Bennett Research Group GitHub page either as a standalone repository or a fork of a personal repository as appropriate.</li> <li>Datasets be adequately documentated with metadata and a clear path of provenance. Datasets used for publications which are not prohibitively large should be published via public repositories (i.e. zenodo; figshare; hydroshare)</li> <li>Provide documentation, whether in code or via technical writeups, of mathematical methods developed or employed in projects where methods development is a significant portion of the research effort.</li> <li>Be clear on the sources of upstream codebases and datasets. Do not claim false ownership over the works of others.</li> </ul>"},{"location":"code_of_conduct/#research-and-workplace-expectations","title":"Research and Workplace Expectations","text":"<p>A large component of all research careers, particularly during graduate schools, is in developing an independent work ethic, drive to build new tools and understanding, and developing a unique taste for research approaches and problems. These higher ideals are often developed alongside considerable hardship including the development of imposter syndrome, a deep sense of career uncertainty, and financial insecurity. To recognize a troubling fact: Conducting research often comes in fits and starts, from scientific, emotional, and financial perspectives. As such, building a strong, collaborative research community is crucial to the success of all of our members. </p> <p>I (Andrew, as the group lead) respect and recognise that many group members will have external personal obligations and responsibilties that not only go beyond, but may supercede, your obligations to your research and/or studies. I hope that you feel comfortable in communicating such matters to me personally, but also want to make space for you to exercise judgement in such matters. To strike a balance between your research obligations and other external affairs I am fully supportive of remote work when communicated generally. I expect a reasonable amount of work hours to be conducted within the Arizona time zone between the hours of roughly 8am to 6pm, and preferably between 10am to 4pm. I expect you will be responsive during these hours at least 3 days a week via email or slack, with obvious exceptions for coursework and travel. I pledge to be similarly available and make my calendar public to all funded students and collaborators.</p> <p>You are highly encouraged to take/use holiday/leave as you see fit, but please let me know when you expect to take leave as soon as possible. A benefit of your studies/work with the group will be external travel to present at conferences or work with collaborators. I am highly supportive of \"piggy-backing\" off of these trips to take vacations or other forms of leave so that you can experience the world as you work. Similarly, if there are regions of the world that you wish to develop collaborations, let me know and I will do my best to find opportunities for funding travel and make connections.</p>"},{"location":"code_of_conduct/#group-meetings-and-individual-meetings","title":"Group meetings and individual meetings","text":"<p>Each term I will schedule an individual meeting for at least 30 minutes per week and a group meeting for an hour a week for all group members. Group members funded on external projects may be asked to participate in meetings with external partners which will be coordinated as funding as developed.</p>"},{"location":"contributing/","title":"Contributing to the group docs","text":"<p>This site is built with mkdocs using the mkdocs-material theme. To get the latest state of the docs you can simply clone them as:</p> <pre><code>git clone https://github.com/BennettHydroLab/group_docs.git\n</code></pre> <p>If you are an authorized group member you should have direct push/commit access. If you are an external collaborator you may need to interact with our docs via a pull request.</p> <p>As an authorized user, you should be able to push new edits to the documentation by commiting your changes to the <code>main</code> branche and then running <code>mkdocs gh-deploy</code> from your local environment.</p>"},{"location":"administrative/1_courses/","title":"Recommended courses &amp; plan of study","text":""},{"location":"administrative/1_courses/#choosing-a-phd-minor","title":"Choosing a PhD Minor","text":"<p>If you are pursuing a PhD at the University of Arizona you are required to complete a PhD minor as a part of your studies. This is generally a 9-12 credit supplementary set of classes that support your research interests.</p> <p>Some natural/common PhD minors for our group are listed below:</p> <ul> <li>Statistics and data science: 12 credits, but broad range of choices</li> <li>Remote sensing and spatial analysis: 12 credits</li> <li>Information: 9 credits from INFO 500+ courses</li> <li>Geosciences: No specific webpage link, but possibly 9 credits of GEOS 500+ courses</li> <li>Geography: 12 credits, but 3 can be independent study</li> <li>Environmental Science: 9 credits, courses not specifically enumerated.</li> </ul>"},{"location":"administrative/2_exams/","title":"Exam overview, preparation, and logistics","text":""},{"location":"administrative/2_exams/#qualifying-exam","title":"Qualifying exam","text":""},{"location":"administrative/2_exams/#comprehensive-exam","title":"Comprehensive exam","text":""},{"location":"administrative/2_exams/#thesisdissertation-defence","title":"Thesis/dissertation defence","text":""},{"location":"administrative/3_travel/","title":"Travel","text":""},{"location":"administrative/3_travel/#travel-authorization","title":"Travel authorization","text":""},{"location":"administrative/3_travel/#booking-traveltransportation","title":"Booking travel/transportation","text":""},{"location":"administrative/3_travel/#booking-lodging","title":"Booking lodging","text":""},{"location":"administrative/3_travel/#reimbursement","title":"Reimbursement","text":""},{"location":"administrative/3_travel/#general-travel-advice","title":"General travel advice","text":""},{"location":"administrative/4_misc/","title":"Other useful stuff","text":""},{"location":"computing/1_computing_environments/","title":"Setting up a streamlined computing environment","text":""},{"location":"computing/1_computing_environments/#setting-up-your-ssh-config","title":"Setting up your <code>ssh</code> config","text":"<p>This code snippet is used to configure an SSH connection.</p> <p>The SSH configuration file allows you to define various settings for SSH connections, such as host aliases, port numbers, and identity files. This file is typically located at ~/.ssh/config.</p> <p>To create a starter SSH config, follow these tips:</p> <ol> <li>Open a terminal or command prompt.</li> <li>Navigate to your home directory by running the command <code>cd ~</code>.</li> <li>Create a new file named <code>config</code> in the <code>.ssh</code> directory by running the command <code>touch ~/.ssh/config</code>.</li> <li>Open the <code>config</code> file in a text editor of your choice.</li> <li>Add the desired SSH configuration settings using the following format:</li> </ol> <pre><code>Host &lt;alias&gt;\n     HostName &lt;hostname&gt;\n     Port &lt;port&gt;\n     User &lt;username&gt;\n     IdentityFile &lt;path_to_private_key&gt;\n     LocalForward &lt;connection_port&gt; localhost:&lt;connection_port&gt;\n     ControlMaster auto\n     ControlPersis yes\n</code></pre> <p>Replace <code>&lt;alias&gt;</code> with a unique name for the host alias, <code>&lt;hostname&gt;</code> with the IP address or domain name of the remote server, <code>&lt;port&gt;</code> with the SSH port number (default is 22, usually you can omit this), <code>&lt;username&gt;</code> with your username on the remote server, and <code>&lt;path_to_private_key&gt;</code> with the path to your private key file. </p> <p>The <code>LocalForward</code> part is useful for when you need to connect to a web application running on the remote server, such as Tensorboard or the dask dashboard. Once your application is running you can connect to it on your local machine by pointing your web browser to <code>localhost:&lt;connection_port&gt;</code>. You may have to play around with the number used for <code>&lt;connection_port&gt;</code>, as different systems use different ports for system applications.</p> <p>Setting <code>ControlMaster</code> and <code>ControlPersist</code> are just useful for when you want to have multiple connections to the same server, so we suggest generally setting them as specified above, though this is not strictly necessary.</p> <ol> <li>Save the <code>config</code> file.</li> </ol> <p>You can now use the defined host aliases in your SSH commands to connect to remote servers easily.</p> <p>Note</p> <p>Make sure to set appropriate permissions for the <code>config</code> file by running the command <code>chmod 600 ~/.ssh/config</code> to ensure it is only readable by you.</p>"},{"location":"computing/1_computing_environments/#passwordless-login-with-ssh-keys","title":"Passwordless login with ssh keys","text":"<p>Setting up passwordless login with SSH keys allows you to securely authenticate with remote servers without having to enter a password each time. Here's how you can set it up:</p> <ol> <li> <p>Generate an SSH key pair on your local machine if you don't already have one. You can do this by running the command <code>ssh-keygen</code> in your terminal. This will generate a public key (<code>id_rsa.pub</code>) and a private key (<code>id_rsa</code>) in the <code>~/.ssh</code> directory.</p> </li> <li> <p>Copy the public key to the remote server by running the command <code>ssh-copy-id &lt;username&gt;@&lt;hostname&gt;</code>. Replace <code>&lt;username&gt;</code> with your username on the remote server and <code>&lt;hostname&gt;</code> with the IP address or domain name of the remote server. This command will copy your public key to the <code>~/.ssh/authorized_keys</code> file on the remote server, allowing you to authenticate using your private key.</p> </li> <li> <p>Test the passwordless login by running the command <code>ssh &lt;username&gt;@&lt;hostname&gt;</code>. You should be able to log in without entering a password.</p> </li> </ol> <p>With passwordless login set up, you can now easily and securely connect to remote servers using SSH keys.</p> <p>Note</p> <p>Make sure to keep your private key (<code>id_rsa</code>) secure and never share it with anyone. If your private key is compromised, an attacker could gain unauthorized access to any remote servers you have set this up for. We suggest setting permissions to <code>600</code> in the same way as is recommended in the note on the ssh config section.</p>"},{"location":"computing/1_computing_environments/#using-tmux-for-persistent-sessions","title":"Using <code>tmux</code> for persistent sessions","text":"<p><code>tmux</code> is a powerful terminal multiplexer that allows you to create and manage multiple terminal sessions within a single window. It provides a way to keep your sessions running even if you disconnect from the server or close your terminal.</p> <p>Here are some basic usage tips for <code>tmux</code>:</p> <ol> <li> <p>Start a new <code>tmux</code> session by running the command <code>tmux</code> in your terminal.</p> </li> <li> <p>Once inside <code>tmux</code>, you can create new windows by pressing <code>Ctrl+b</code> followed by <code>c</code>. This will open a new window with a shell prompt.</p> </li> <li> <p>To switch between windows, use <code>Ctrl+b</code> followed by a number key corresponding to the window you want to switch to. For example, <code>Ctrl+b 0</code> will switch to window 0, <code>Ctrl+b 1</code> will switch to window 1, and so on.</p> </li> <li> <p>You can also navigate between windows using <code>Ctrl+b</code> followed by <code>n</code> (next window) or <code>p</code> (previous window).</p> </li> <li> <p>To split a window into multiple panes, use <code>Ctrl+b</code> followed by <code>%</code> (vertical split) or <code>\"</code> (horizontal split). This will divide the current window into two panes, allowing you to run different commands side by side.</p> </li> <li> <p>To navigate between panes, use <code>Ctrl+b</code> followed by an arrow key in the direction you want to move. For example, <code>Ctrl+b</code> followed by <code>Left Arrow</code> will move to the pane on the left.</p> </li> <li> <p>To resize panes, press <code>Ctrl+b</code> followed by <code>Ctrl+Arrow Key</code> in the direction you want to resize. For example, <code>Ctrl+b</code> followed by <code>Ctrl+Right Arrow</code> will increase the width of the current pane.</p> </li> <li> <p>If you need to detach from a <code>tmux</code> session and leave it running in the background, press <code>Ctrl+b</code> followed by <code>d</code>. You can then safely close your terminal or disconnect from the server.</p> </li> <li> <p>To reattach to a detached <code>tmux</code> session, use the command <code>tmux attach</code> in your terminal.</p> </li> </ol> <p>These are just some of the basic <code>tmux</code> commands to get you started. <code>tmux</code> has many more features and customization options, so be sure to check out the documentation for more advanced usage.</p> <p>Tip</p> <p>The default <code>tmux</code> experience is not very user friendly - we suggest customizing your experience by creating a configuration file at <code>~/.tmux.conf</code>. This tutorial is a great starting point. Similarly, you can see Andrew's configuration here.</p>"},{"location":"computing/1_computing_environments/#accessing-remote-jupyter-servers","title":"Accessing remote <code>jupyter</code> servers","text":"<p>To access a remote Jupyter server using forwarded ports, you can follow these steps:</p> <ol> <li>Start by configuring your SSH connection to forward ports. To see how to do this see the section on setting up your ssh config.</li> <li> <p>Connect to the remote server using SSH by running the command <code>ssh &lt;alias&gt;</code> in your terminal. This will establish the SSH connection and forward the specified ports.</p> </li> <li> <p>Once connected to the remote server, start the Jupyter server by running the command <code>jupyter lab --no-browser --port=&lt;remote_port&gt;</code>. Replace <code>&lt;remote_port&gt;</code> with the same port number specified in the SSH config file.</p> </li> <li> <p>The Jupyter server will start and display a URL in the terminal. Copy the URL and access it from your local machine's web browser.</p> </li> </ol> <p>You should now be able to access and use the remote Jupyter server from your local machine using forwarded ports.</p>"},{"location":"computing/1_computing_environments/#installing-conda-on-remote-servers","title":"Installing <code>conda</code> on remote servers","text":"<p>We suggest you install <code>conda</code> using the <code>miniconda</code> distribution, which provides a minimal starting set. You can find the official instructions for installing <code>miniconda</code> here</p> <p>To install Miniconda on a remote server, follow these steps:</p> <pre><code>mkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm -rf ~/miniconda3/miniconda.sh\n</code></pre> <p>Following installation you can initialize <code>conda</code> for your shell with:</p> <pre><code>~/miniconda3/bin/conda init bash\n</code></pre> <p>After the initialization, activate the Miniconda environment by running the following command. This step only needs to be done the first time. Alternatively you can simply log out and log back in. This will update your shell with the necessary environment variables.</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"computing/2_computing_systems/","title":"Computing resources","text":"<p>This page provides links to common computing platforms that the group uses. For information about how to configure your environment see this page.</p>"},{"location":"computing/2_computing_systems/#group-server-ocotillo","title":"Group server (<code>ocotillo</code>)","text":"<p>The group maintains a separate computing server that has the following resources:</p> <ul> <li>2x AMD Epyc 7763 64 Core CPU</li> <li>1 TB system memory (RAM)</li> <li>8x NVIDIA RTX A6000 Ada GPU</li> <li>50 TB storage</li> </ul> <p>It can be accessed from <code>ocotillo.has.arizona.edu</code> while on the UA network or VPN. You will need to have an account manually set up to access <code>ocotillo</code>. If you haven't had this happen already, talk to Andrew to set up a meeting to gain access.</p> <p>Note</p> <p>Usage of this system is unmanaged, and it is expected that you are concious of your resource usage. If you are going to be running large jobs on this system that take significant resources (i.e. &gt;500 GB memory, &gt; 32 cores, or &gt;2 GPUs), please coordinate your runs via our slack channel.</p>"},{"location":"computing/2_computing_systems/#accessing-ocotillo-from-outside-of-ua","title":"Accessing <code>ocotillo</code> from outside of UA","text":"<p>To access outside of the UA network we suggest setting an entry in your ssh config as: <pre><code>Host ocotillo\n    User &lt;your_username&gt;\n    HostName ocotillo.has.arizona.edu\n    ProxyJump filexfer.hpc.arizona.edu\n    LocalForward &lt;port1&gt; localhost:&lt;port1&gt;\n    LocalForward &lt;port2&gt; localhost:&lt;port2&gt;\n    ControlMaster auto\n    ControlPersist yes\n</code></pre></p> <p>This will do a \"proxy jump\" through the file transfer server from the UA HPC center. You will need a UA HPC account for this to work. You can set as many port forwards as you would like, depending on how many simultaneous web apps you tend to monitor. If you set up passwordless login via ssh-keys make sure to set up passwordless login for both <code>filexfer.hpc.arizona.edu</code> and <code>ocotillo.has.arizona.edu</code> separately.</p>"},{"location":"computing/2_computing_systems/#ua-high-performance-computing-hpc","title":"UA High Performance Computing (HPC)","text":"<p>The University of Arizona runs the High Performance Computing systems that all students, staff, and faculty are able to use. For more detailed information about available resources see the UA HPC Documentation website here.</p> <p>When signing up for an account use Andrew's email as your sponsor.</p>"},{"location":"computing/2_computing_systems/#tips-for-streamlining-ua-hpc-access","title":"Tips for streamlining UA HPC access","text":"<p>The default setup on the UA HPC system is a bit unconventional and can make standard workflows awkward to run. This is due to there being the \"bastion\" node which is separate from the \"login\" node, meaning when you first ssh to <code>hpc.arizona.edu</code> you cannot get right on with work, but have to choose a default system to jump to. This can be worked around by jumping directly to the <code>junonia</code> server. We use a similar method to accessing <code>ocotillo</code> by jumping through the file transfer server. You can still switch systems using their respective named commands (e.g. <code>puma</code> or <code>ocelote</code>). This can be accomplished by setting up your ssh config:</p> <pre><code>Host junonia\n    User &lt;your_username&gt;\n    HostName junonia.hpc.arizona.edu\n    ProxyJump filexfer.hpc.arizona.edu\n    LocalForward &lt;port1&gt; localhost:&lt;port1&gt;\n    LocalForward &lt;port2&gt; localhost:&lt;port2&gt;\n    ControlMaster auto\n    ControlPersist yes\n</code></pre>"},{"location":"computing/2_computing_systems/#some-helpful-aliases-to-set-up","title":"Some helpful aliases to set up","text":""},{"location":"computing/2_computing_systems/#accessing-jupyter-servers-running-in-interactive-sessions-from-vscode","title":"Accessing jupyter servers running in interactive sessions from VSCode","text":""},{"location":"computing/2_computing_systems/#cyverse","title":"CyVerse","text":""},{"location":"computing/2_computing_systems/#free-resources","title":"Free resources","text":""},{"location":"computing/2_computing_systems/#google-colab","title":"Google Colab","text":""},{"location":"computing/2_computing_systems/#github-spaces","title":"GitHub Spaces","text":""},{"location":"computing/2_computing_systems/#binder","title":"Binder","text":""},{"location":"computing/2_computing_systems/#cloud-computing-paid","title":"Cloud computing (paid)","text":""},{"location":"computing/2_computing_systems/#runpod","title":"Runpod","text":""},{"location":"computing/2_computing_systems/#google-amazon-microsoft","title":"Google, Amazon, Microsoft","text":""},{"location":"computing/3_data/","title":"Datasets","text":""},{"location":"computing/3_data/#hydrologic-datasets","title":"Hydrologic datasets","text":""},{"location":"computing/3_data/#meteorologic-datasets","title":"Meteorologic datasets","text":""},{"location":"computing/3_data/#climate-datasets","title":"Climate datasets","text":""},{"location":"computing/3_data/#geologic-datasets","title":"Geologic datasets","text":""},{"location":"computing/3_data/#engineered-systems","title":"Engineered systems","text":""},{"location":"computing/4_models/","title":"Modeling tools","text":""},{"location":"computing/5_interesting_packages/","title":"Software packages of interest","text":""},{"location":"computing/6_communities/","title":"Communities of practice","text":""},{"location":"computing/6_communities/#broader-earth-data-science-communities","title":"Broader Earth Data Science Communities","text":"<p>Please use this section to keep track of wider community-led organizations that develop and promote data sciences methods for Earth and environmental applications.</p> <ul> <li>Pangeo</li> <li>Project Pythia</li> <li>Fatiando a Terra</li> <li>Consortium of Universities for the Advancement of Hydrologic Science</li> </ul>"},{"location":"computing/6_communities/#ua-data-science-campus-resources","title":"UA Data Science Campus Resources","text":"<p>Please use this section to keep track of University of Arizona specific resources. This can be other meetups/events, communities, opportunities, resources, or locations that connect us to the broader campus activities around data science and Earth science.</p> <ul> <li>Data Science Institute</li> <li>High Performance Computing</li> <li>CyVerse</li> <li>Institute for Computation and Data-Enabled Insight</li> </ul>"},{"location":"computing/7_howto/","title":"Tutorials and how-tos","text":""},{"location":"computing/7_howto/#useful-snippets","title":"Useful snippets","text":"<ul> <li>Testing if your PyTorch installation has CUDA correctly installed: <code>python -c \"import torch; print(torch.cuda.is_available())\"</code></li> <li>Showing the size of all files/folders in your current directory <code>for d in $(ls); do du -sh $d; done</code></li> </ul>"},{"location":"computing/7_howto/#made-by-the-group","title":"Made by the group","text":"<p>This section is for resources which have been created by members or close collaborators.</p> <ul> <li>High resolution predictions of global snow using recurrent neural networks: This is a machine learning tutorial that highlights using large-scale climate projections and recurrent neural networks to model snow.</li> <li>AI for physics-inspired hydrology modeling: An end to end implementation of hybrid modeling techniques that blend machine learning with differential equations for hydrologic modeling. Open source implementation here.</li> </ul>"},{"location":"computing/7_howto/#from-around-the-web","title":"From around the web","text":""},{"location":"computing/7_howto/#visualization","title":"Visualization","text":"<ul> <li>20 simple, distinct colors: A simple, interactive tool to picking basic colors for data visualization.</li> <li>Color Brewer: Color advice for cartography</li> </ul>"},{"location":"computing/7_howto/#machine-learning","title":"Machine Learning","text":"<ul> <li>A Recipe for Training Neural Networks: Practical (and often unspoken) advice for how to train deep learning models in the wild.</li> <li>Understanding LSTM Networks: An illustrated guide to understanding Long-Short Term Memory Networks, a popular variant of recurrent neural networks for environmental timeseries modeling.</li> </ul>"},{"location":"resources/1_advice/","title":"Advice and tips for doing research","text":""},{"location":"resources/2_fellowships/","title":"Fellowships, grants, and ways to apply for funding","text":""},{"location":"resources/2_fellowships/#opportunities-at-the-university-of-arizona","title":"Opportunities at the University of Arizona","text":""},{"location":"resources/2_fellowships/#external-opportunities","title":"External opportunities","text":""},{"location":"resources/3_textbooks/","title":"Free textbooks","text":""},{"location":"resources/3_textbooks/#machine-learning","title":"Machine learning","text":"<ul> <li>Deep Learning: The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free. </li> <li>Physics Based Deep Learning JupyterBook: An introductory look at incorporating physical constraints into deep learning.</li> </ul>"},{"location":"resources/3_textbooks/#mathematics","title":"Mathematics","text":"<ul> <li>Numerical Methods for Scientific Computing: A comprehensive graduate-level text on the mathematical theory and application of scientific computing algorithms. Other programming language implementations available here</li> <li>Algorithms for Optimization: A broad introduction to algorithms for optimal decision making under uncertainty. </li> </ul>"},{"location":"resources/3_textbooks/#hydrology","title":"Hydrology","text":"<ul> <li>Introduction to Hydrology: A google form that can be filled out to download Steve Margulis's introductory textbook on hydrologic sciences.</li> <li>Groundwater: The seminal textbook by Freeze and Cherry on all things groundwater.</li> </ul>"},{"location":"resources/3_textbooks/#computational-geoscience-data-analysis","title":"Computational geoscience &amp; data analysis","text":"<ul> <li>Machine Learning in the Geosciences: The GeoScience MAchine Learning Resources and Training (GeoSMART) framework provides an educational pathway and a foundation in open source scientific ecosystems and progresses through general ML theory, toolkits, and deployment on Cloud computing.</li> <li>Artificial Intelligence for Earth Science: Artificial Intelligence in Earth Science: Best Practices and Fundamental Challenges provides a comprehensive, step-by-step guide to AI workflows for solving problems in Earth Science.</li> <li>Introduction to Python in Earth Science Data Analysis: Numerous step-by-step code examples in the field of Earth Sciences Allows proficient use of Python in visualizing, analyzing, and modelling geological data Specifically minded for teaching Python to geologists</li> </ul>"},{"location":"resources/3_textbooks/#data-visualization","title":"Data visualization","text":"<ul> <li>Scientific Visualization: Python + Matplotlib: An open access book on scientific visualization using python and matplotlib </li> </ul>"}]}